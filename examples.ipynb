{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just import statements\n",
    "import time\n",
    "import numpy as np\n",
    "import simple_wta, convex_relaxation, regret_matching, spectral_clustering, ahuja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'simple_wta.WTAProblem'>\n",
      "(175,)\n",
      "(300, 175)\n"
     ]
    }
   ],
   "source": [
    "# creating a random WTA problem\n",
    "n_weapons = 300\n",
    "n_targets = 175\n",
    "prob = simple_wta.random_wta_factory(n_weapons, n_targets)\n",
    "print(type(prob))\n",
    "\n",
    "# target values are stored in WTAProblem.v\n",
    "print(np.shape(prob.v))\n",
    "\n",
    "# pk data is stored in WTAProblem.p\n",
    "print(np.shape(prob.p))\n",
    "\n",
    "# specific WTA problems can be constructed by passing a\n",
    "# value vector and pk matrix to the class constructor\n",
    "copy_problem = simple_wta.WTAProblem(prob.v.copy(),prob.p.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution found in 0.003 seconds.\n",
      "objective value 318.5\n"
     ]
    }
   ],
   "source": [
    "# An upper bound on the optimal WTA objective can be found \n",
    "# by replacing the WTA problem with a knapsack problem, and optimizing\n",
    "# in greedy fashion.\n",
    "\n",
    "# this is implemented according to the Ahuja paper\n",
    "\n",
    "# \"combinatorial lower-bounding (clb) maximum marginal return (mmr) algorithm\"\n",
    "t0 = time.perf_counter()\n",
    "x = simple_wta.clb_mmr_alg(prob)\n",
    "t1 = time.perf_counter()\n",
    "print(\"solution found in %.3f seconds.\" % (t1-t0))\n",
    "print(\"objective value %.1f\" % prob.objective(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution found in 88.913 seconds.\n",
      "objective value 22.0\n"
     ]
    }
   ],
   "source": [
    "# now gonna fuck with the ahuja code\n",
    "t0 = time.perf_counter()\n",
    "x = ahuja.optimize(prob)\n",
    "t1 = time.perf_counter()\n",
    "print(\"solution found in %.3f seconds.\" % (t1-t0))\n",
    "print(\"objective value %.1f\" % prob.objective(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\spear\\OneDrive - UW\\code\\wta\\examples.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/spear/OneDrive%20-%20UW/code/wta/examples.ipynb#ch0000004?line=5'>6</a>\u001b[0m rounds \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/spear/OneDrive%20-%20UW/code/wta/examples.ipynb#ch0000004?line=6'>7</a>\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/spear/OneDrive%20-%20UW/code/wta/examples.ipynb#ch0000004?line=7'>8</a>\u001b[0m x,P,R \u001b[39m=\u001b[39m regret_matching\u001b[39m.\u001b[39;49mlearning_dynamics(prob, rounds)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/spear/OneDrive%20-%20UW/code/wta/examples.ipynb#ch0000004?line=8'>9</a>\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/spear/OneDrive%20-%20UW/code/wta/examples.ipynb#ch0000004?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39msolution found in \u001b[39m\u001b[39m%.1f\u001b[39;00m\u001b[39m seconds.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (t1\u001b[39m-\u001b[39mt0))\n",
      "File \u001b[1;32mc:\\Users\\spear\\OneDrive - UW\\code\\wta\\regret_matching.py:44\u001b[0m, in \u001b[0;36mlearning_dynamics\u001b[1;34m(prob, N)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,N):\n\u001b[0;32m     42\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[0;32m     43\u001b[0m         \u001b[39m# calculate average regret of player i\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m         R[i,:] \u001b[39m=\u001b[39m average_regret(prob,i,k,R[i,:],x)\n\u001b[0;32m     45\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[0;32m     46\u001b[0m         x[i],P[i,:] \u001b[39m=\u001b[39m action_update(R[i,:])\n",
      "File \u001b[1;32mc:\\Users\\spear\\OneDrive - UW\\code\\wta\\regret_matching.py:18\u001b[0m, in \u001b[0;36maverage_regret\u001b[1;34m(prob, i, k, rk, xk)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(m):\n\u001b[0;32m     17\u001b[0m     xi \u001b[39m=\u001b[39m j\n\u001b[1;32m---> 18\u001b[0m     r[j] \u001b[39m=\u001b[39m (k\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m/\u001b[39mk \u001b[39m*\u001b[39m rk[j] \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39mk \u001b[39m*\u001b[39m (wlu(prob,i,xi,xk[idx])\u001b[39m-\u001b[39mwlu(prob,i,xk[i],xk[idx]))\n\u001b[0;32m     19\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# We can use a multi-agent reinforcement learning algorithm\n",
    "# directly on the original problem.\n",
    "\n",
    "# Run regret-matching for 50 rounds and sample a random action profile\n",
    "# from a probability distribution derived from the regret vectors.\n",
    "rounds = 50\n",
    "t0 = time.perf_counter()\n",
    "x,P,R = regret_matching.learning_dynamics(prob, rounds)\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "print(\"solution found in %.1f seconds.\" % (t1-t0))\n",
    "print(\"solution time divided by # weapons %.1f\" % ((t1-t0)/n_weapons))\n",
    "print(\"mixed strategy objective value %.1f\" % prob.mixed_objective(P))\n",
    "print(\"argmax stragey objective value %.1f\" % prob.objective(np.argmax(P,1)))\n",
    "\n",
    "# this is an improvement over the maximum-marginal-return approach\n",
    "# but comes at significant computaitonal cost.\n",
    "\n",
    "# However, in practice the bulk of the computations are done in parallel\n",
    "# (each weapon only computes their own regret)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution found in 33.0 seconds.\n",
      "solution time divided by (# weapons) 0.132\n",
      "mixed strategy objective value 133.9\n",
      "argmax stragey objective value 133.7\n"
     ]
    }
   ],
   "source": [
    "# now we will demonstrate scaling improvements afforded by\n",
    "# partitioning the large WTA problem into smaller subproblems.\n",
    "\n",
    "# first we will do this randomly.\n",
    "\n",
    "n_clusters = int(np.sqrt(n_weapons))\n",
    "sub_problems, coalitions, missions = spectral_clustering.random_reduction(prob, n_clusters)\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "rounds = 150\n",
    "actions = [regret_matching.learning_dynamics(prob,rounds)[1] for prob in sub_problems]\n",
    "value1 = np.sum([sub_problems[i].mixed_objective(actions[i]) for i in range(n_clusters)])\n",
    "value2 = np.sum([sub_problems[i].objective(np.argmax(actions[i],1)) for i in range(n_clusters)])\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "print(\"solution found in %.1f seconds.\" % (t1-t0))\n",
    "print(\"solution time divided by (# weapons) %.3f\" % ((t1-t0)/(n_weapons)))\n",
    "print(\"mixed strategy objective value %.1f\" % value1)\n",
    "print(\"argmax stragey objective value %.1f\" % value2)\n",
    "\n",
    "# its apparent that the divide-and-conquer strategy drastically accelerates\n",
    "# learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution found in 37.6 seconds.\n",
      "solution time divided by (# weapons) 0.150\n",
      "mixed strategy objective value 70.0\n",
      "argmax stragey objective value 68.1\n"
     ]
    }
   ],
   "source": [
    "# finally we will demonstrate the objective improvements when spectral clustering is applied\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "sub_problems, coalitions, missions = spectral_clustering.reduce_problem(prob, n_clusters)\n",
    "rounds = 150\n",
    "actions = [regret_matching.learning_dynamics(prob,rounds)[1] for prob in sub_problems]\n",
    "value1 = np.sum([sub_problems[i].mixed_objective(actions[i]) for i in range(n_clusters)])\n",
    "value2 = np.sum([sub_problems[i].objective(np.argmax(actions[i],1)) for i in range(n_clusters)])\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "print(\"solution found in %.1f seconds.\" % (t1-t0))\n",
    "print(\"solution time divided by (# weapons) %.3f\" % ((t1-t0)/(n_weapons)))\n",
    "print(\"mixed strategy objective value %.1f\" % value1)\n",
    "print(\"argmax stragey objective value %.1f\" % value2)\n",
    "\n",
    "# obviously, spectral clustering is better than random clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution found in 1.6 seconds.\n",
      "value 47.9\n"
     ]
    }
   ],
   "source": [
    "# what about ahuja algorithm on random clusters?\n",
    "t0 = time.perf_counter()\n",
    "sub_problems, coalitions, missions = spectral_clustering.random_reduction(prob, n_clusters)\n",
    "rounds = 100\n",
    "actions = [ahuja.optimize(prob) for prob in sub_problems]\n",
    "value = np.sum([sub_problems[i].objective(actions[i]) for i in range(n_clusters)])\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "print(\"solution found in %.1f seconds.\" % (t1-t0))\n",
    "print(\"value %.1f\" % value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:959: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, order=order, subok=subok, copy=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution found in 3.136 seconds.\n",
      "objective value 29.7\n"
     ]
    }
   ],
   "source": [
    "# what about ahuja algorithm on spectral clusters? \n",
    "\n",
    "t0 = time.perf_counter()\n",
    "sub_problems, coalitions, missions = spectral_clustering.reduce_problem(prob, n_clusters)\n",
    "actions = [ahuja.optimize(prob) for prob in sub_problems]\n",
    "value = np.sum([sub_problems[i].objective(actions[i]) for i in range(n_clusters)])\n",
    "t1 = time.perf_counter()\n",
    "print(\"solution found in %.3f seconds.\" % (t1-t0))\n",
    "print(\"objective value %.1f\" % value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:959: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, order=order, subok=subok, copy=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n"
     ]
    },
    {
     "ename": "NodeNotFound",
     "evalue": "Source 0 not in G",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNodeNotFound\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\spear\\OneDrive - UW\\code\\wta\\examples.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/spear/OneDrive%20-%20UW/code/wta/examples.ipynb#ch0000012?line=31'>32</a>\u001b[0m     tstart \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/spear/OneDrive%20-%20UW/code/wta/examples.ipynb#ch0000012?line=32'>33</a>\u001b[0m     sub_problems, coalitions, missions \u001b[39m=\u001b[39m spectral_clustering\u001b[39m.\u001b[39mrandom_reduction(problems[i], L[i])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/spear/OneDrive%20-%20UW/code/wta/examples.ipynb#ch0000012?line=33'>34</a>\u001b[0m     f2[i,j] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum([p\u001b[39m.\u001b[39mobjective(ahuja\u001b[39m.\u001b[39moptimize(p)) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m sub_problems])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/spear/OneDrive%20-%20UW/code/wta/examples.ipynb#ch0000012?line=34'>35</a>\u001b[0m     t2[i,j] \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\u001b[39m-\u001b[39mtstart\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/spear/OneDrive%20-%20UW/code/wta/examples.ipynb#ch0000012?line=36'>37</a>\u001b[0m tstart \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n",
      "\u001b[1;32mc:\\Users\\spear\\OneDrive - UW\\code\\wta\\examples.ipynb Cell 10'\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/spear/OneDrive%20-%20UW/code/wta/examples.ipynb#ch0000012?line=31'>32</a>\u001b[0m     tstart \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/spear/OneDrive%20-%20UW/code/wta/examples.ipynb#ch0000012?line=32'>33</a>\u001b[0m     sub_problems, coalitions, missions \u001b[39m=\u001b[39m spectral_clustering\u001b[39m.\u001b[39mrandom_reduction(problems[i], L[i])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/spear/OneDrive%20-%20UW/code/wta/examples.ipynb#ch0000012?line=33'>34</a>\u001b[0m     f2[i,j] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum([p\u001b[39m.\u001b[39mobjective(ahuja\u001b[39m.\u001b[39;49moptimize(p)) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m sub_problems])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/spear/OneDrive%20-%20UW/code/wta/examples.ipynb#ch0000012?line=34'>35</a>\u001b[0m     t2[i,j] \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\u001b[39m-\u001b[39mtstart\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/spear/OneDrive%20-%20UW/code/wta/examples.ipynb#ch0000012?line=36'>37</a>\u001b[0m tstart \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n",
      "File \u001b[1;32mc:\\Users\\spear\\OneDrive - UW\\code\\wta\\ahuja.py:143\u001b[0m, in \u001b[0;36moptimize\u001b[1;34m(prob, maxiters, ftol_abs, verbose)\u001b[0m\n\u001b[0;32m    141\u001b[0m iters \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     cycle \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49mfind_negative_cycle(DG, \u001b[39m0\u001b[39;49m)\n\u001b[0;32m    144\u001b[0m     \u001b[39m#print(cycle)\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     assignment_changed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py:2197\u001b[0m, in \u001b[0;36mfind_negative_cycle\u001b[1;34m(G, source, weight)\u001b[0m\n\u001b[0;32m   2194\u001b[0m weight \u001b[39m=\u001b[39m _weight_function(G, weight)\n\u001b[0;32m   2195\u001b[0m pred \u001b[39m=\u001b[39m {source: []}\n\u001b[1;32m-> 2197\u001b[0m v \u001b[39m=\u001b[39m _inner_bellman_ford(G, [source], weight, pred\u001b[39m=\u001b[39;49mpred)\n\u001b[0;32m   2198\u001b[0m \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2199\u001b[0m     \u001b[39mraise\u001b[39;00m nx\u001b[39m.\u001b[39mNetworkXError(\u001b[39m\"\u001b[39m\u001b[39mNo negative cycles detected.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py:1384\u001b[0m, in \u001b[0;36m_inner_bellman_ford\u001b[1;34m(G, sources, weight, pred, dist, heuristic)\u001b[0m\n\u001b[0;32m   1382\u001b[0m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m sources:\n\u001b[0;32m   1383\u001b[0m     \u001b[39mif\u001b[39;00m s \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m G:\n\u001b[1;32m-> 1384\u001b[0m         \u001b[39mraise\u001b[39;00m nx\u001b[39m.\u001b[39mNodeNotFound(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSource \u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m}\u001b[39;00m\u001b[39m not in G\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1386\u001b[0m \u001b[39mif\u001b[39;00m pred \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1387\u001b[0m     pred \u001b[39m=\u001b[39m {v: [] \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m sources}\n",
      "\u001b[1;31mNodeNotFound\u001b[0m: Source 0 not in G"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "I'm going to compare solution quality and run time of several different\n",
    "methods at various problem scales\n",
    "\"\"\"\n",
    "\n",
    "# number of clusters \n",
    "L = np.array([10,12,14,16])\n",
    "# number of weapons\n",
    "N = L**2\n",
    "# number of targets\n",
    "M = np.array(0.75*N,dtype=int)\n",
    "# WTA problems\n",
    "problems = [simple_wta.random_wta_factory(N[i],M[i]) for i in range(len(N))]\n",
    "# baseline performance for comparison\n",
    "baseline = [problems[i].objective(simple_wta.clb_mmr_alg(problems[i])) for i in range(len(N))]\n",
    "f1 = np.zeros(len(N))          # objective value for ahuja's method on full problem\n",
    "f2 = np.zeros((len(N),100))    # objective value for ahuja's method on 100 random coalitions\n",
    "f3 = np.zeros(len(N))          # objective value for ahuja's method with spectral clustering\n",
    "# runnign times\n",
    "t1 = np.zeros(len(N))\n",
    "t2 = np.zeros((len(N),100))\n",
    "t3 = np.zeros(len(N))\n",
    "\n",
    "for i in range(len(problems)):\n",
    "    print(i)\n",
    "    tstart = time.perf_counter()\n",
    "    f1[i] = problems[i].objective(ahuja.optimize(problems[i]))\n",
    "    t1[i] = time.perf_counter()-tstart\n",
    "\n",
    "    for j in range(100):\n",
    "        print(j)\n",
    "        tstart = time.perf_counter()\n",
    "        sub_problems, coalitions, missions = spectral_clustering.random_reduction(problems[i], L[i])\n",
    "        f2[i,j] = np.sum([p.objective(ahuja.optimize(p)) for p in sub_problems])\n",
    "        t2[i,j] = time.perf_counter()-tstart\n",
    "    \n",
    "    tstart = time.perf_counter()\n",
    "    sub_problems, coalitions, missions = spectral_clustering.reduce_problem(problems[i], L[i])\n",
    "    f3[i] = np.sum([p.objective(ahuja.optimize(p)) for p in sub_problems])\n",
    "    t3[i] = time.perf_counter()-tstart\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
